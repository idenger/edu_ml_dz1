# Проект по предсказанию стоимости автомобилей

---

## Часть 1

**обучить модель регрессии для предсказания стоимости автомобилей;**

---

## Часть 1. Простейший EDA и обработка признаков

1) Обнаружил присутствие пропусков, а также дубликатов.  
2) Проанализировал статистики датасета — нашел небольшую асимметрию в данных и выбросы по некоторым признакам.  
3) Нашел и удалил повторяющиеся строки. Привел несколько способов поиска скрытых дублей, но таких не было обнаружено в датасете.  
4) Поработал с типами данных, описывающих признаки. Убрал единицы измерения для числовых признаков. Проделал работу с парсингом и разделением признака **"torque"** на два отдельных **"torque"** и **"max_torque_rpm"**.  
5) Заполнил найденные ранее пропуски медианными значениями.  
6) Привел значения признаков **"engnine"** и **"seats"** к `int`.  
7) После всех манипуляций получил на выходе практически те же статистики, с небольшими изменениями.  
8) С помощью библиотеки **seabron** визуализировал попарные распределения признаков и визуально определел некоторые зависимости признаков и целевой переменной.  
9) С помощью библиотеки **seabron** построил тепловую карту признаков, используя значения коэффициентов корреляции Пирсона. Определил сильную корреляцию с целевой переменной признаков **"year"**, **"max_power"**, **"engine"**.  
10) Написал функцию расчета корреляции Спирмена. Её расчеты получились идентичны расчетам библиотечной функции из pandas. Тепловая карта получилась похожей с картой по Пирсону. Попробовал в работе **Phik**, который дополнил карту категориальными признаками. Он занулил корреляцию **km_driven** и **selling_price**, но разбив вручную эти признаки на бины, получил нормальный результат.

---

## Часть 2. Модель только на вещественных признаках

11) Подготовил из исходных датафреймов данные для обучения.  

12) Обучил Линейную регрессию. Метрики показали средние результаты:

```
R2 TRAIN:  0.60117
R2 TEST:   0.60065
RMSE TRAIN: 338112
RMSE TEST:  479119
```

13) Реализован собственные функции расчета R2 и adjusted-R2.  
14) Обучил стандартизатор на тренировочных данных.  
15) Убучив Линейную модель на стандартизированных данных, определил наиболее важный признак — **max_power**.  

16) Обучил Lasso регрессию на наших нормализованных данных.

```
R2 TRAIN:  0.60117
R2 TEST:   0.60065
RMSE TRAIN: 338112
RMSE TEST:  479120
```

17) Применил методику автоматического подбора гиперпараметров моделей **Lasso** и **ElasticNet** регрессий с помощью **GridSearchCV**.  
Так, например, для Lasso — обучилось 1600 модели и подобралась лучшая, которая занулила **"engine"** и **"torque"**:

```
Lasso(alpha=2000, selection='random', tol=0.1, random_state=42)
```

18) Поэксперементировал с моделью с L0-регулирацией. Качество получилось похуже:

```
R2 TRAIN:  0.59477
R2 TEST:   0.58350
RMSE TRAIN: 340811
RMSE TEST:  489298
```

Но применив **GridSearchCV**, удалось построить лучшую модель:

```
L0LinearRegression(threshold=0.001, lr=0.005, n_iter=2000)
```

с метриками

```
R2 TRAIN:  0.60113
R2 TEST:   0.60032
RMSE TRAIN: 338126
RMSE TEST:  479316
```

---

## Часть 3. Добавляем категориальные фичи

19) С категориальными признаками пришлось поработать. Так переработал **"name"**, чтобы на выходе получить всего 195 уникальных значения.  
20) Категориальные признаки закодировал методом **OneHot-кодирования**. Итого получилось 248 признаков в датасете.  
21) Удалил один столбец для каждого признака при кодировании, чтобы уйти от линейной зависимости столбцов. Если коэффициенты у признаков близки к нулю, то можно их удалить, или за нас это же может сделать регуляризация.  

22) С помощью **GridSearchCV** обучил **Ridge** модели на полученном датасете, включающим закодированные категориальные признаки. Получил лучшую модель:

```
Ridge(alpha=0.1, tol=0.1)
```

с метриками

```
R2 TRAIN:  0.86050
R2 TEST:   0.88171
RMSE TRAIN: 199961
RMSE TEST:  260750
```

Добавление новых категориальных признаков позволило составить более точную модель! Метрики значительно улучшились.

---

## Часть 4. Feature Engineering + Бизнес

*) С помощью **GridSearchCV** обучил **HuberRegressor** модели на датасете, включающим закодированные категориальные признаки. И получил такие метрики, что оказалось хуже, чем предыдущая Ridge:

```
R2 TRAIN:  0.83351
R2 TEST:   0.65895
RMSE TRAIN: 218450
RMSE TEST:  442765
```

*) Затем поработал с датасетом. Заменил год выпуска на возраст, убрал названия машин, Мощность пролагорифмировал. Также применил логарифм к целевой переменной.  
В итоге получили модель, близкую по качеству к оптимальной Ridge:

```
R2 TRAIN:  0.89284
R2 TEST:   0.84839
RMSE TRAIN: 175253
RMSE TEST:  295205
```

23) Написал функцию для подсчета новой метрики — доли прогнозов, отличающихся от реальных цен не более чем на заданное количество процентов.  
24) Также реализовал другую метрику для бизнеса и определил, что лучше всего задачу решает обученная ранее Ridge модель.

---

## Часть 5. Создание интерактивного приложения на Streamlit

```
https://edumldz1git-jebbgwn4encxityxghrn8v.streamlit.app/
```

- Создал удобное мини приложение для предсказания стоимости автомобилей.  
- Можно либо указать праметры автомобиля вручную, либо загрузить список в виде csv-файла.  
- Выявил некоторые проблемы с масштабированием графиков. Надо будет уделить этому процессу больше времени.  
- Ручное предсказание при уже загруженном csv-файле делается долго, так как перерисовывается весь предыдущий анализ. Планирую это доработать.

---
